{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25045d8",
   "metadata": {},
   "source": [
    "**Inputs**\n",
    "- `experiment/resources/lists/con_run1.csv`\n",
    "- `experiment/resources/lists/abs_run1.csv`\n",
    "- `experiment/resources/lists/con_run2.csv`\n",
    "- `experiment/resources/lists/abs_run2.csv`\n",
    "- `stimuli_selection/lexicons/subtlex-pl.csv`\n",
    "- `stimuli_selection/lexicons/anpw_r.csv`\n",
    "\n",
    "**Outputs**\n",
    "- `stimuli_selection/reports/stimuli_report_run1.csv`\n",
    "- `stimuli_selection/reports/stimuli_report_run2.csv`\n",
    "- `stimuli_selection/reports/stimuli_report_all.csv`\n",
    "- `stimuli_selection/reports/stimuli_distributions/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a199b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_project_root(start: Path | None = None) -> Path:\n",
    "    p = (start or Path.cwd()).resolve()\n",
    "    for candidate in [p, *p.parents]:\n",
    "        if (candidate / \"experiment\" / \"resources\" / \"lists\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\n",
    "        \"Project root not found. Expected folder: experiment/resources/lists \"\n",
    "        \"somewhere above the current working directory.\"\n",
    "    )\n",
    "\n",
    "ROOT = find_project_root()\n",
    "\n",
    "LISTS_DIR = ROOT / \"experiment\" / \"resources\" / \"lists\"\n",
    "LEX_DIR = ROOT / \"stimuli_selection\" / \"lexicons\"\n",
    "REPORTS_DIR = ROOT / \"stimuli_selection\" / \"reports\"\n",
    "FIG_DIR = REPORTS_DIR / \"figures\"\n",
    "\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "LIST_FILES = {\n",
    "    \"con_run1\": LISTS_DIR / \"con_run1.csv\",\n",
    "    \"abs_run1\": LISTS_DIR / \"abs_run1.csv\",\n",
    "    \"con_run2\": LISTS_DIR / \"con_run2.csv\",\n",
    "    \"abs_run2\": LISTS_DIR / \"abs_run2.csv\",\n",
    "}\n",
    "\n",
    "SUBTLEX_FILE = LEX_DIR / \"subtlex-pl.csv\"\n",
    "ANPW_FILE = LEX_DIR / \"anpw_r.csv\"\n",
    "\n",
    "CSV_ENCODING_LISTS = \"utf-8-sig\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502ccf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norm_word(x: str) -> str:\n",
    "    return str(x).strip().lower()\n",
    "\n",
    "def count_syllables_pl(word: str) -> int:\n",
    "    \"\"\"Very simple syllable count for Polish (heuristic).\"\"\"\n",
    "    w = _norm_word(word)\n",
    "    vowels = \"aeiouyąęó\"\n",
    "    groups = re.findall(rf\"[{vowels}]+\", w)\n",
    "    return max(1, len(groups)) if w else 0\n",
    "\n",
    "def cohen_d(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    y = y[~np.isnan(y)]\n",
    "    if len(x) < 2 or len(y) < 2:\n",
    "        return np.nan\n",
    "    nx, ny = len(x), len(y)\n",
    "    vx, vy = np.var(x, ddof=1), np.var(y, ddof=1)\n",
    "    sp = math.sqrt(((nx - 1) * vx + (ny - 1) * vy) / (nx + ny - 2))\n",
    "    return (np.mean(x) - np.mean(y)) / sp if sp > 0 else np.nan\n",
    "\n",
    "def bootstrap_ci_d(x: np.ndarray, y: np.ndarray, n_boot: int = 3000, seed: int = 123) -> tuple[float, float]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    y = y[~np.isnan(y)]\n",
    "    if len(x) < 2 or len(y) < 2:\n",
    "        return (np.nan, np.nan)\n",
    "    ds = []\n",
    "    for _ in range(n_boot):\n",
    "        xb = rng.choice(x, size=len(x), replace=True)\n",
    "        yb = rng.choice(y, size=len(y), replace=True)\n",
    "        ds.append(cohen_d(xb, yb))\n",
    "    lo, hi = np.nanpercentile(ds, [2.5, 97.5])\n",
    "    return float(lo), float(hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa13881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      word condition  run                          stimFile list_name  \\\n",
       " 0  autobus       CON    1  resources/audio/con_run1_001.wav  con_run1   \n",
       " 1   cygaro       CON    1  resources/audio/con_run1_002.wav  con_run1   \n",
       " 2  łańcuch       CON    1  resources/audio/con_run1_003.wav  con_run1   \n",
       " 3     kosz       CON    1  resources/audio/con_run1_004.wav  con_run1   \n",
       " 4    małpa       CON    1  resources/audio/con_run1_005.wav  con_run1   \n",
       " \n",
       "   word_norm  \n",
       " 0   autobus  \n",
       " 1    cygaro  \n",
       " 2   łańcuch  \n",
       " 3      kosz  \n",
       " 4     małpa  ,\n",
       " (96, 6))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trial lists\n",
    "\n",
    "dfs = {}\n",
    "for key, path in LIST_FILES.items():\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing list file: {path}\")\n",
    "    df = pd.read_csv(path, encoding=CSV_ENCODING_LISTS)\n",
    "    if \"word\" not in df.columns:\n",
    "        raise ValueError(f\"{path} must contain 'word' column\")\n",
    "    df[\"list_name\"] = key\n",
    "    df[\"run\"] = 1 if \"run1\" in key else 2\n",
    "    df[\"condition\"] = \"CON\" if key.startswith(\"con\") else \"ABS\"\n",
    "    df[\"word_norm\"] = df[\"word\"].map(_norm_word)\n",
    "    dfs[key] = df\n",
    "\n",
    "lists = pd.concat(dfs.values(), ignore_index=True)\n",
    "lists.head(), lists.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc19d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>condition</th>\n",
       "      <th>run</th>\n",
       "      <th>stimFile</th>\n",
       "      <th>list_name</th>\n",
       "      <th>word_norm</th>\n",
       "      <th>nchar</th>\n",
       "      <th>syllables</th>\n",
       "      <th>concretness_M</th>\n",
       "      <th>Valence_M</th>\n",
       "      <th>arousal_M</th>\n",
       "      <th>ageOfAquisition_M</th>\n",
       "      <th>Number of Letters</th>\n",
       "      <th>zipf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autobus</td>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "      <td>resources/audio/con_run1_001.wav</td>\n",
       "      <td>con_run1</td>\n",
       "      <td>autobus</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.60</td>\n",
       "      <td>5.18</td>\n",
       "      <td>3.02</td>\n",
       "      <td>6.18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.347849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cygaro</td>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "      <td>resources/audio/con_run1_002.wav</td>\n",
       "      <td>con_run1</td>\n",
       "      <td>cygaro</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1.92</td>\n",
       "      <td>5.18</td>\n",
       "      <td>3.42</td>\n",
       "      <td>9.64</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.697874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>łańcuch</td>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "      <td>resources/audio/con_run1_003.wav</td>\n",
       "      <td>con_run1</td>\n",
       "      <td>łańcuch</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.56</td>\n",
       "      <td>3.28</td>\n",
       "      <td>7.62</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.821329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kosz</td>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "      <td>resources/audio/con_run1_004.wav</td>\n",
       "      <td>con_run1</td>\n",
       "      <td>kosz</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.66</td>\n",
       "      <td>4.54</td>\n",
       "      <td>3.28</td>\n",
       "      <td>6.78</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.649674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>małpa</td>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "      <td>resources/audio/con_run1_005.wav</td>\n",
       "      <td>con_run1</td>\n",
       "      <td>małpa</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.74</td>\n",
       "      <td>5.34</td>\n",
       "      <td>3.88</td>\n",
       "      <td>7.44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.948048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word condition  run                          stimFile list_name  \\\n",
       "0  autobus       CON    1  resources/audio/con_run1_001.wav  con_run1   \n",
       "1   cygaro       CON    1  resources/audio/con_run1_002.wav  con_run1   \n",
       "2  łańcuch       CON    1  resources/audio/con_run1_003.wav  con_run1   \n",
       "3     kosz       CON    1  resources/audio/con_run1_004.wav  con_run1   \n",
       "4    małpa       CON    1  resources/audio/con_run1_005.wav  con_run1   \n",
       "\n",
       "  word_norm  nchar  syllables  concretness_M  Valence_M  arousal_M  \\\n",
       "0   autobus      7          3           1.60       5.18       3.02   \n",
       "1    cygaro      6          3           1.92       5.18       3.42   \n",
       "2   łańcuch      7          2           2.00       4.56       3.28   \n",
       "3      kosz      4          1           1.66       4.54       3.28   \n",
       "4     małpa      5          2           1.74       5.34       3.88   \n",
       "\n",
       "   ageOfAquisition_M  Number of Letters      zipf  \n",
       "0               6.18                7.0  4.347849  \n",
       "1               9.64                6.0  3.697874  \n",
       "2               7.62                7.0  3.821329  \n",
       "3               6.78                4.0  3.649674  \n",
       "4               7.44                5.0  3.948048  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load lexicons\n",
    "\n",
    "if not SUBTLEX_FILE.exists():\n",
    "    raise FileNotFoundError(f\"Missing SUBTLEX file: {SUBTLEX_FILE}\")\n",
    "if not ANPW_FILE.exists():\n",
    "    raise FileNotFoundError(f\"Missing ANPW file: {ANPW_FILE}\")\n",
    "\n",
    "sub = pd.read_csv(SUBTLEX_FILE, sep=None, engine=\"python\", encoding=\"utf-8\")\n",
    "sub.columns = [c.strip() for c in sub.columns]\n",
    "sub[\"word_norm\"] = sub[\"spelling\"].map(_norm_word) if \"spelling\" in sub.columns else sub.iloc[:, 0].map(_norm_word)\n",
    "\n",
    "zipf_col = None\n",
    "for cand in [\"zipf.freq\", \"zipf_freq\", \"zipf\", \"Zipf\", \"avg.zipf.freq.sn\", \"zipf.freq.sn.sum\"]:\n",
    "    if cand in sub.columns:\n",
    "        zipf_col = cand\n",
    "        break\n",
    "\n",
    "anpw = pd.read_csv(ANPW_FILE, sep=None, engine=\"python\", encoding=\"utf-8\")\n",
    "anpw.columns = [c.strip() for c in anpw.columns]\n",
    "anpw_word_col = \"polish word\" if \"polish word\" in anpw.columns else anpw.columns[1]\n",
    "anpw[\"word_norm\"] = anpw[anpw_word_col].map(_norm_word)\n",
    "\n",
    "def to_float_series(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(s.astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "\n",
    "for col in [\"concretness_M\", \"Valence_M\", \"arousal_M\", \"ageOfAquisition_M\", \"Number of Letters\"]:\n",
    "    if col in anpw.columns:\n",
    "        anpw[col] = to_float_series(anpw[col])\n",
    "\n",
    "lists[\"nchar\"] = lists[\"word\"].astype(str).str.len()\n",
    "lists[\"syllables\"] = lists[\"word\"].map(count_syllables_pl)\n",
    "\n",
    "feat = lists.merge(\n",
    "    anpw[[\"word_norm\"] + [c for c in [\"concretness_M\", \"Valence_M\", \"arousal_M\", \"ageOfAquisition_M\", \"Number of Letters\"] if c in anpw.columns]],\n",
    "    on=\"word_norm\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "if zipf_col is not None:\n",
    "    feat = feat.merge(sub[[\"word_norm\", zipf_col]], on=\"word_norm\", how=\"left\")\n",
    "    feat = feat.rename(columns={zipf_col: \"zipf\"})\n",
    "else:\n",
    "    feat[\"zipf\"] = np.nan\n",
    "\n",
    "feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf61db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>condition</th>\n",
       "      <th>n_unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ABS</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CON</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ABS</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>CON</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run condition  n_unique_words\n",
       "0    1       ABS              24\n",
       "1    1       CON              24\n",
       "2    2       ABS              24\n",
       "3    2       CON              24"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity checks\n",
    "\n",
    "feat.groupby([\"run\", \"condition\"])[\"word_norm\"].nunique().rename(\"n_unique_words\").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e502aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROL_VARS = [\"nchar\", \"syllables\", \"zipf\", \"Valence_M\", \"arousal_M\", \"ageOfAquisition_M\"]\n",
    "MANIP_VAR = \"concretness_M\"\n",
    "\n",
    "def run_tests(df: pd.DataFrame, var: str) -> dict:\n",
    "    x = df.loc[df[\"condition\"] == \"CON\", var].astype(float).to_numpy()\n",
    "    y = df.loc[df[\"condition\"] == \"ABS\", var].astype(float).to_numpy()\n",
    "    x = x[~np.isnan(x)]\n",
    "    y = y[~np.isnan(y)]\n",
    "\n",
    "    out = {\n",
    "        \"var\": var,\n",
    "        \"n_CON\": len(x),\n",
    "        \"n_ABS\": len(y),\n",
    "        \"mean_CON\": np.mean(x) if len(x) else np.nan,\n",
    "        \"mean_ABS\": np.mean(y) if len(y) else np.nan,\n",
    "        \"sd_CON\": np.std(x, ddof=1) if len(x) > 1 else np.nan,\n",
    "        \"sd_ABS\": np.std(y, ddof=1) if len(y) > 1 else np.nan,\n",
    "    }\n",
    "\n",
    "    if len(x) and len(y):\n",
    "        ks = stats.ks_2samp(x, y, alternative=\"two-sided\", mode=\"auto\")\n",
    "        out[\"ks_stat\"] = float(ks.statistic)\n",
    "        out[\"ks_p\"] = float(ks.pvalue)\n",
    "    else:\n",
    "        out[\"ks_stat\"] = np.nan\n",
    "        out[\"ks_p\"] = np.nan\n",
    "\n",
    "    if len(x) > 1 and len(y) > 1:\n",
    "        lev = stats.levene(x, y, center=\"median\")\n",
    "        out[\"levene_stat\"] = float(lev.statistic)\n",
    "        out[\"levene_p\"] = float(lev.pvalue)\n",
    "    else:\n",
    "        out[\"levene_stat\"] = np.nan\n",
    "        out[\"levene_p\"] = np.nan\n",
    "\n",
    "    if len(x) > 1 and len(y) > 1:\n",
    "        tt = stats.ttest_ind(x, y, equal_var=False, nan_policy=\"omit\")\n",
    "        out[\"t_stat_welch\"] = float(tt.statistic)\n",
    "        out[\"t_p_welch\"] = float(tt.pvalue)\n",
    "    else:\n",
    "        out[\"t_stat_welch\"] = np.nan\n",
    "        out[\"t_p_welch\"] = np.nan\n",
    "\n",
    "    if len(x) and len(y):\n",
    "        mw = stats.mannwhitneyu(x, y, alternative=\"two-sided\")\n",
    "        out[\"mw_u\"] = float(mw.statistic)\n",
    "        out[\"mw_p\"] = float(mw.pvalue)\n",
    "    else:\n",
    "        out[\"mw_u\"] = np.nan\n",
    "        out[\"mw_p\"] = np.nan\n",
    "\n",
    "    out[\"cohen_d_CON_minus_ABS\"] = float(cohen_d(x, y))\n",
    "    lo, hi = bootstrap_ci_d(x, y, n_boot=3000, seed=202)\n",
    "    out[\"d_ci95_low\"] = lo\n",
    "    out[\"d_ci95_high\"] = hi\n",
    "    return out\n",
    "\n",
    "def make_report(df: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for v in CONTROL_VARS + [MANIP_VAR]:\n",
    "        if v in df.columns:\n",
    "            rows.append(run_tests(df, v))\n",
    "    rep = pd.DataFrame(rows)\n",
    "    rep.insert(0, \"scope\", label)\n",
    "    return rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0067f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinga\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:579: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\kinga\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:579: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  scope                var  n_CON  n_ABS  mean_CON  mean_ABS    sd_CON  \\\n",
       " 0  run1              nchar     24     24  6.375000  6.416667  1.636871   \n",
       " 1  run1          syllables     24     24  2.291667  2.291667  0.624094   \n",
       " 2  run1               zipf     24     23  3.915522  3.931515  0.481821   \n",
       " 3  run1          Valence_M     24     24  5.382500  5.615833  0.692452   \n",
       " 4  run1          arousal_M     24     24  3.409167  4.380833  0.558631   \n",
       " 5  run1  ageOfAquisition_M     24     24  7.465833  8.946667  0.996227   \n",
       " 6  run1      concretness_M     24     24  1.770417  5.700000  0.155744   \n",
       " \n",
       "      sd_ABS   ks_stat          ks_p  levene_stat      levene_p  t_stat_welch  \\\n",
       " 0  1.767254  0.041667  1.000000e+00     0.017332  8.958335e-01     -0.084739   \n",
       " 1  0.624094  0.000000  1.000000e+00     0.000000  1.000000e+00      0.000000   \n",
       " 2  0.460334  0.112319  9.900658e-01     0.021655  8.836648e-01     -0.116370   \n",
       " 3  1.489978  0.375000  6.780335e-02     6.090300  1.737261e-02     -0.695727   \n",
       " 4  0.979307  0.500000  4.320850e-03    10.639830  2.089041e-03     -4.222125   \n",
       " 5  1.158750  0.541667  1.401357e-03     1.118117  2.958459e-01     -4.747364   \n",
       " 6  0.953169  1.000000  6.202011e-14    34.275837  4.781414e-07    -19.932461   \n",
       " \n",
       "       t_p_welch   mw_u          mw_p  cohen_d_CON_minus_ABS  d_ci95_low  \\\n",
       " 0  9.328384e-01  291.0  9.580800e-01              -0.024462   -0.575073   \n",
       " 1  1.000000e+00  288.0  1.000000e+00               0.000000   -0.597276   \n",
       " 2  9.078772e-01  264.5  8.149055e-01              -0.033923   -0.637070   \n",
       " 3  4.915464e-01  203.0  8.137921e-02              -0.200839   -0.923962   \n",
       " 4  1.535940e-04  113.5  3.325843e-04              -1.218822   -1.944359   \n",
       " 5  2.123743e-05   96.5  8.175071e-05              -1.370446   -2.158457   \n",
       " 6  1.548478e-16    0.0  3.030813e-09              -5.754006   -7.404773   \n",
       " \n",
       "    d_ci95_high  \n",
       " 0     0.558642  \n",
       " 1     0.602173  \n",
       " 2     0.521550  \n",
       " 3     0.347121  \n",
       " 4    -0.708794  \n",
       " 5    -0.797045  \n",
       " 6    -4.915536  ,\n",
       "   scope                var  n_CON  n_ABS  mean_CON  mean_ABS    sd_CON  \\\n",
       " 0  run2              nchar     24     24  5.750000  5.791667  1.750776   \n",
       " 1  run2          syllables     24     24  2.000000  1.958333  0.722315   \n",
       " 2  run2               zipf     24     24  4.051426  4.121916  0.523405   \n",
       " 3  run2          Valence_M     24     24  5.825833  5.029167  0.661868   \n",
       " 4  run2          arousal_M     24     24  3.421667  4.550000  0.417150   \n",
       " 5  run2  ageOfAquisition_M     24     24  6.742500  8.525417  0.869749   \n",
       " 6  run2      concretness_M     24     24  1.891667  5.448333  0.144934   \n",
       " \n",
       "      sd_ABS   ks_stat          ks_p  levene_stat  levene_p  t_stat_welch  \\\n",
       " 0  1.693444  0.041667  1.000000e+00     0.021082  0.885191     -0.083803   \n",
       " 1  0.690253  0.041667  1.000000e+00     0.080139  0.778379      0.204309   \n",
       " 2  0.502966  0.125000  9.941612e-01     0.040010  0.842343     -0.475729   \n",
       " 3  1.806981  0.333333  1.398226e-01    14.253694  0.000457      2.028106   \n",
       " 4  1.032481  0.666667  2.340323e-05    14.250924  0.000457     -4.963941   \n",
       " 5  1.354243  0.583333  4.056559e-04     4.432184  0.040758     -5.426879   \n",
       " 6  0.889493  1.000000  6.202011e-14    24.342190  0.000011    -19.333769   \n",
       " \n",
       "       t_p_welch   mw_u          mw_p  cohen_d_CON_minus_ABS  d_ci95_low  \\\n",
       " 0  9.335773e-01  281.5  8.997497e-01              -0.024192   -0.602154   \n",
       " 1  8.390149e-01  297.0  8.475724e-01               0.058979   -0.524504   \n",
       " 2  6.365226e-01  265.0  6.426892e-01              -0.137331   -0.725328   \n",
       " 3  5.180330e-02  345.5  2.397518e-01               0.585464    0.050706   \n",
       " 4  2.514518e-05   92.0  5.530006e-05              -1.432966   -2.081607   \n",
       " 5  3.183279e-06   80.5  1.965878e-05              -1.566605   -2.376630   \n",
       " 6  3.128523e-16    0.0  3.015984e-09              -5.581178   -7.643873   \n",
       " \n",
       "    d_ci95_high  \n",
       " 0     0.549559  \n",
       " 1     0.640161  \n",
       " 2     0.412921  \n",
       " 3     1.207610  \n",
       " 4    -0.974051  \n",
       " 5    -1.021567  \n",
       " 6    -4.674918  ,\n",
       "       scope                var  n_CON  n_ABS  mean_CON  mean_ABS    sd_CON  \\\n",
       " 0  all_runs              nchar     48     48  6.062500  6.104167  1.706137   \n",
       " 1  all_runs          syllables     48     48  2.145833  2.125000  0.683843   \n",
       " 2  all_runs               zipf     48     47  3.983474  4.028741  0.502378   \n",
       " 3  all_runs          Valence_M     48     48  5.604167  5.322500  0.706540   \n",
       " 4  all_runs          arousal_M     48     48  3.415417  4.465417  0.487761   \n",
       " 5  all_runs  ageOfAquisition_M     48     48  7.104167  8.736042  0.994709   \n",
       " 6  all_runs      concretness_M     48     48  1.831042  5.574167  0.160945   \n",
       " \n",
       "      sd_ABS   ks_stat          ks_p  levene_stat      levene_p  t_stat_welch  \\\n",
       " 0  1.741112  0.020833  1.000000e+00     0.000000  1.000000e+00     -0.118421   \n",
       " 1  0.672404  0.020833  1.000000e+00     0.040976  8.400208e-01      0.150501   \n",
       " 2  0.486919  0.116135  8.510728e-01     0.026897  8.700847e-01     -0.445975   \n",
       " 3  1.664971  0.270833  5.876302e-02    20.107623  2.066997e-05      1.078932   \n",
       " 4  0.999146  0.541667  8.289542e-07    24.853533  2.816848e-06     -6.542818   \n",
       " 5  1.264852  0.541667  8.289542e-07     4.189161  4.347501e-02     -7.026138   \n",
       " 6  0.920843  1.000000  3.107971e-28    59.397776  1.308781e-11    -27.741830   \n",
       " \n",
       "       t_p_welch    mw_u          mw_p  cohen_d_CON_minus_ABS  d_ci95_low  \\\n",
       " 0  9.059868e-01  1142.5  9.465574e-01              -0.024173   -0.420591   \n",
       " 1  8.806918e-01  1172.0  8.744640e-01               0.030721   -0.356108   \n",
       " 2  6.566523e-01  1056.5  5.971521e-01              -0.091487   -0.500603   \n",
       " 3  2.847062e-01  1106.5  7.415601e-01               0.220236   -0.193033   \n",
       " 4  9.256709e-09   422.0  8.989447e-08              -1.335547   -1.796961   \n",
       " 5  4.098103e-10   366.5  8.793248e-09              -1.434204   -1.970206   \n",
       " 6  5.636034e-32     0.0  3.191348e-17              -5.662777   -6.745155   \n",
       " \n",
       "    d_ci95_high  \n",
       " 0     0.372327  \n",
       " 1     0.444009  \n",
       " 2     0.322354  \n",
       " 3     0.616172  \n",
       " 4    -0.959764  \n",
       " 5    -0.997109  \n",
       " 6    -5.041723  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_run1 = make_report(feat[feat[\"run\"] == 1].copy(), \"run1\")\n",
    "rep_run2 = make_report(feat[feat[\"run\"] == 2].copy(), \"run2\")\n",
    "rep_all = make_report(feat.copy(), \"all_runs\")\n",
    "\n",
    "rep_run1, rep_run2, rep_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57aec58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - C:\\Users\\kinga\\Documents\\Blindbrain\\4. Courses\\fMRI - design of the experiment and data analysis\\cognes-auditory-1back-pilot\\stimuli_selection\\reports\\stimuli_report_run1.csv\n",
      " - C:\\Users\\kinga\\Documents\\Blindbrain\\4. Courses\\fMRI - design of the experiment and data analysis\\cognes-auditory-1back-pilot\\stimuli_selection\\reports\\stimuli_report_run2.csv\n",
      " - C:\\Users\\kinga\\Documents\\Blindbrain\\4. Courses\\fMRI - design of the experiment and data analysis\\cognes-auditory-1back-pilot\\stimuli_selection\\reports\\stimuli_report_all.csv\n"
     ]
    }
   ],
   "source": [
    "rep_run1.to_csv(REPORTS_DIR / \"stimuli_report_run1.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "rep_run2.to_csv(REPORTS_DIR / \"stimuli_report_run2.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "rep_all.to_csv(REPORTS_DIR / \"stimuli_report_all.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", REPORTS_DIR / \"stimuli_report_run1.csv\")\n",
    "print(\" -\", REPORTS_DIR / \"stimuli_report_run2.csv\")\n",
    "print(\" -\", REPORTS_DIR / \"stimuli_report_all.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84eed4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== all_runs ==\n",
      "nchar: KS p=1, Levene p=1, Welch p=0.906\n",
      "syllables: KS p=1, Levene p=0.84, Welch p=0.881\n",
      "zipf: KS p=0.851, Levene p=0.87, Welch p=0.657\n",
      "Valence_M: KS p=0.0588, Levene p=2.07e-05, Welch p=0.285\n",
      "arousal_M: KS p=8.29e-07, Levene p=2.82e-06, Welch p=9.26e-09\n",
      "ageOfAquisition_M: KS p=8.29e-07, Levene p=0.0435, Welch p=4.1e-10\n",
      "concretness_M: d=-5.66 [-6.75, -5.04], Welch p=5.64e-32\n"
     ]
    }
   ],
   "source": [
    "def summarize(rep: pd.DataFrame, scope: str) -> None:\n",
    "    r = rep[rep[\"scope\"] == scope].set_index(\"var\")\n",
    "\n",
    "    def fmt_p(p):\n",
    "        return f\"{p:.3g}\" if pd.notna(p) else \"NA\"\n",
    "\n",
    "    print(f\"== {scope} ==\")\n",
    "    for v in CONTROL_VARS:\n",
    "        if v not in r.index:\n",
    "            continue\n",
    "        print(f\"{v}: KS p={fmt_p(r.loc[v,'ks_p'])}, Levene p={fmt_p(r.loc[v,'levene_p'])}, Welch p={fmt_p(r.loc[v,'t_p_welch'])}\")\n",
    "    if MANIP_VAR in r.index:\n",
    "        d = r.loc[MANIP_VAR, \"cohen_d_CON_minus_ABS\"]\n",
    "        lo = r.loc[MANIP_VAR, \"d_ci95_low\"]\n",
    "        hi = r.loc[MANIP_VAR, \"d_ci95_high\"]\n",
    "        print(f\"{MANIP_VAR}: d={d:.2f} [{lo:.2f}, {hi:.2f}], Welch p={fmt_p(r.loc[MANIP_VAR,'t_p_welch'])}\")\n",
    "\n",
    "summarize(rep_all, \"all_runs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55b8ad22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figures to: C:\\Users\\kinga\\Documents\\Blindbrain\\4. Courses\\fMRI - design of the experiment and data analysis\\cognes-auditory-1back-pilot\\stimuli_selection\\reports\\figures\n"
     ]
    }
   ],
   "source": [
    "# distributions saved as PNG\n",
    "\n",
    "PLOT_VARS = [\"nchar\", \"syllables\", \"zipf\", \"concretness_M\"]\n",
    "\n",
    "def plot_var(df: pd.DataFrame, var: str, label: str) -> None:\n",
    "    d = df[[\"condition\", var]].dropna()\n",
    "    x = d.loc[d[\"condition\"] == \"CON\", var].astype(float).to_numpy()\n",
    "    y = d.loc[d[\"condition\"] == \"ABS\", var].astype(float).to_numpy()\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.hist(x, bins=10, alpha=0.6, label=\"CON\")\n",
    "    plt.hist(y, bins=10, alpha=0.6, label=\"ABS\")\n",
    "    plt.title(f\"{label}: {var}\")\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.legend()\n",
    "    out = FIG_DIR / f\"{label}_{var}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "for label, df_ in [(\"run1\", feat[feat[\"run\"] == 1]), (\"run2\", feat[feat[\"run\"] == 2]), (\"all\", feat)]:\n",
    "    for v in PLOT_VARS:\n",
    "        if v in df_.columns:\n",
    "            plot_var(df_, v, label)\n",
    "\n",
    "print(\"Saved figures to:\", FIG_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
